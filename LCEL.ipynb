{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16c4afc",
   "metadata": {},
   "source": [
    "###  LANGCHAIN APPLICATION , LCEL (LANGCHAIN EXPRESSION LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5853dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#settting environment for os\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import groq\n",
    "groq_apikey=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c1e0ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000263F86BCFB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000263F8697EC0>, model_name='gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using groq for model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"gemma2-9b-It\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f630f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Message Objects used for conversational type\n",
    "from langchain_core.messages import HumanMessage,SystemMessage \n",
    "\n",
    "message=[\n",
    "      SystemMessage(content=\"Translate the following from english to Spanish\"),\n",
    "      HumanMessage(content=\"Hello! How are you?\")\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "res=model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52bcf4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"¡Hola! ¿Cómo estás? \\n\\n\\nLet me know if you'd like to translate anything else!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 22, 'total_tokens': 47, 'completion_time': 0.045454545, 'prompt_time': 0.002050539, 'queue_time': 0.24518742100000002, 'total_time': 0.047505084}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--5e84ee88-8e77-4030-a1b3-f5902eefa0c8-0', usage_metadata={'input_tokens': 22, 'output_tokens': 25, 'total_tokens': 47})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6e6ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"¡Hola! ¿Cómo estás? \\n\\n\\nLet me know if you'd like to translate anything else!\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# here we are only getting the output not with the other details of the model\n",
    "#might include the exyra details with explanations\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce4b9fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! ¿Cómo estás? \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using LCEL -chain the components\n",
    "#used for getting cleans and final answer\n",
    "chain=model|parser\n",
    "\n",
    "chain.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34a077d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### also\n",
    "## PROMPT TEMPLATES\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_temp=\"Translate the following into {language}\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_temp),\n",
    "     (\"user\",\"{text}\")],\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09cc56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1=prompt.invoke({\"language\":\"French\",\"text\":\"What are you doing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1894fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into French', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What are you doing?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.to_messages() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f8b94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd48efaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Que fais-tu ? \\n\\n\\n(pronounced: kay fay-too?)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# by using prompt template\n",
    "#chaining together with the lCEL components\n",
    "chain.invoke({\"language\":\"French\",\"text\":\"What are you doing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4cbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c0ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92e7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4809b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c757290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d10a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6652f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e91aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f1518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96447ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e725145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240b1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
